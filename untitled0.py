# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DXvLT1qXJkcjT0_u9BXQ4y_55ixbrKKZ
"""

!pip install nltk

import numpy as np
import pandas as pd
import ast
from sklearn.feature_extraction.text import CountVectorizer
import nltk

movies=pd.read_csv('/tmdb_5000_movies.csv')
credits=pd.read_csv('/tmdb_5000_credits.csv')

movies.head()

credits.head()

credits.head(10)['crew']

movies.shape

credits.shape

final_movies=movies.merge(credits,on='title')
final_movies

final_movies.shape

movies['genres'].describe()

movies['genres'].unique()

credits['title'].duplicated().sum()

movies['title'].duplicated().sum()

final_movies['original_language'].value_counts()

"""**Which columns to consider**"""

#Genre, #ID - to fetch movie poster, #Keywords, #title (only english names), overview (summary is similar means movie is similar)
#release_date, #cast, #crew

final_movies=final_movies[['genres','title','movie_id','overview','keywords','cast','crew']]

"""**Creating Tags with preprocessing**"""

#merging cast crew overview keywords after formatting
final_movies.isnull().sum()

final_movies.dropna(inplace=True)

final_movies.duplicated().sum()
#the 3 duplicates from above were the ones without any overview

final_movies.iloc[0].genres

def extract_tags(obj):
  genre_list=[]
  for i in ast.literal_eval(obj):
    genre_list.append(i['name'])
  return genre_list

final_movies['genres']=final_movies['genres'].apply(extract_tags)
final_movies

final_movies['keywords']=final_movies['keywords'].apply(extract_tags)

def extract_actor(obj):
  actor_list=[]
  count=0
  for i in ast.literal_eval(obj):
    if count !=3:
      actor_list.append(i['name'])
      count+=1
    else:
      break
  return actor_list

final_movies['cast']=final_movies['cast'].apply(extract_actor)
final_movies['cast']

final_movies['crew'][0]

def extract_director(obj):
  director=[]
  for i in ast.literal_eval(obj):
    if(i['department']=='Directing' and i['job']=='Director'):
      director.append(i['name'])

  return director

final_movies['crew']=final_movies['crew'].apply(extract_director)

final_movies['crew']

final_movies['overview']=final_movies['overview'].apply(lambda x:x.split())

final_movies

"""**Merging Tags into a paragraph**"""

#merging words

final_movies['genres']=final_movies['genres'].apply(lambda x:[i.replace(" ","") for i in x])
final_movies['cast']=final_movies['cast'].apply(lambda x:[i.replace(" ","") for i in x])
final_movies['crew']=final_movies['crew'].apply(lambda x:[i.replace(" ","") for i in x])
final_movies['keywords']=final_movies['keywords'].apply(lambda x:[i.replace(" ","") for i in x])

final_movies.head()

#merging all columns for tags

final_movies['tags']=final_movies['overview']+final_movies['genres']+final_movies['cast']+final_movies['crew']

final_movies['tags']

preprocessed_df=final_movies[['movie_id','title','tags']]

preprocessed_df['tags']=preprocessed_df['tags'].apply(lambda x:" ".join(x))

preprocessed_df['tags']=preprocessed_df['tags'].apply(lambda x:x.lower())

"""**Tag similarity using vectors and text vectorization using bag of words**"""

#bag of words
#combine all words
#concat strings
#calculate frequency of each word
#extract top 5000 words with the largest frequency
#remove stop words

cv=CountVectorizer(max_features=5000,stop_words='english')

vectors=cv.fit_transform(preprocessed_df['tags']).toarray()

vectors.shape

len(cv.get_feature_names_out())

cv.get_feature_names_out()

#dgits may be useless and accept/accepted are same words so we'll apply stemming

from nltk.stem.porter import PorterStemmer

ps=PorterStemmer()

def stem(text):
  list1=[]
  for i in text.split():
    list1.append(ps.stem(i))
  return " ".join(list1)

preprocessed_df['tags']=preprocessed_df['tags'].apply(stem)

cv=CountVectorizer(max_features=5000,stop_words='english')

vectors=cv.fit_transform(preprocessed_df['tags']).toarray()

cv.get_feature_names_out()

from sklearn.metrics.pairwise import cosine_similarity

similarity_matrix=cosine_similarity(vectors)

index_list=sorted(list(enumerate(similarity_matrix[0])),reverse=True,key=lambda x:x[1])[1:6]
index_list

def recommend(movie):
  index=preprocessed_df[preprocessed_df['title']==movie].index[0]
  distances=similarity_matrix[index]
  movies_index_list=sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]
  for i in movies_index_list:
    print(preprocessed_df.iloc[i[0]].title)

recommend('Avatar')

